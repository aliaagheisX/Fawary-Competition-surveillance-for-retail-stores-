{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 12:19:55.724230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-21 12:19:55.776198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-21 12:19:55.800034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 12:19:55.998156: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 12:19:57.798447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# ----------- local imports ----------- \n",
    "from constants import FACE_ID_TRAIN_PATH, DATA_DIR\n",
    "from Facenet.face_id_dataset import get_train_val_set, get_embedding_from_path\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess train embedding dataframe\n",
    "df_train_embeddings = get_embedding_from_path(\"embeddings/train_embeddings.csv\")\n",
    "\n",
    "train_df, val_df = get_train_val_set(df_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['person'].unique()), len(val_df['person'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Hard mining Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>person</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>[-0.59278923, 0.7828487, -0.6835971, 1.7158566...</td>\n",
       "      <td>person_92</td>\n",
       "      <td>9173.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>[-2.381399, 0.960104, 0.4525168, 1.2529911, 0....</td>\n",
       "      <td>person_19</td>\n",
       "      <td>2887.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>[-0.10098656, -0.5457215, 0.20366341, 1.052844...</td>\n",
       "      <td>person_14</td>\n",
       "      <td>2380.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>[-0.12268988, 0.7154933, -1.0429839, -1.286360...</td>\n",
       "      <td>person_76</td>\n",
       "      <td>7370.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>[0.7124005, -0.28405225, 1.5859838, 0.9142377,...</td>\n",
       "      <td>person_45</td>\n",
       "      <td>4891.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[-1.8333522, -1.125215, -1.4959185, 0.45485142...</td>\n",
       "      <td>person_116</td>\n",
       "      <td>1456.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>[-1.4881357, 1.4335285, -0.18140173, 0.6914673...</td>\n",
       "      <td>person_116</td>\n",
       "      <td>1440.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>[-0.38687825, -1.7119275, -2.0680356, -0.52073...</td>\n",
       "      <td>person_115</td>\n",
       "      <td>1414.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>[-0.6950201, 1.0628453, -1.1542852, -0.7147884...</td>\n",
       "      <td>person_78</td>\n",
       "      <td>7446.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>[-0.17757356, 2.0137675, -0.7703777, -0.004532...</td>\n",
       "      <td>person_35</td>\n",
       "      <td>4140.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5331 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings      person       img\n",
       "6451  [-0.59278923, 0.7828487, -0.6835971, 1.7158566...   person_92  9173.jpg\n",
       "2009  [-2.381399, 0.960104, 0.4525168, 1.2529911, 0....   person_19  2887.jpg\n",
       "1656  [-0.10098656, -0.5457215, 0.20366341, 1.052844...   person_14  2380.jpg\n",
       "5179  [-0.12268988, 0.7154933, -1.0429839, -1.286360...   person_76  7370.jpg\n",
       "3429  [0.7124005, -0.28405225, 1.5859838, 0.9142377,...   person_45  4891.jpg\n",
       "...                                                 ...         ...       ...\n",
       "1003  [-1.8333522, -1.125215, -1.4959185, 0.45485142...  person_116  1456.jpg\n",
       "992   [-1.4881357, 1.4335285, -0.18140173, 0.6914673...  person_116  1440.jpg\n",
       "975   [-0.38687825, -1.7119275, -2.0680356, -0.52073...  person_115  1414.jpg\n",
       "5232  [-0.6950201, 1.0628453, -1.1542852, -0.7147884...   person_78  7446.jpg\n",
       "2898  [-0.17757356, 2.0137675, -0.7703777, -0.004532...   person_35  4140.jpg\n",
       "\n",
       "[5331 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
